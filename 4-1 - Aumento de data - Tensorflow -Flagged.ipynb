{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNT7RjLSKER3"
      },
      "source": [
        "# Aumento de data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se hará uso de Tensorflow y el arreglo de estilo \"n-gram\" para crear nuevas cadenas de texto a partir del entrenamiento\r\n",
        "y predicción de un modelo que permita generar una palabra a partir de sus anteriores.\r\n",
        "\r\n",
        "Fuente: https://www.youtube.com/watch?v=ZMudJXhsUpY&list=PLQY2H8rRoyvzDbLUZkbudP-MFQZwNmU4S&index=6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uQwh_5j9xiHB"
      },
      "outputs": [],
      "source": [
        "# Importar librerías necesarias. \r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras import regularizers\r\n",
        "import tensorflow.keras.utils as ku\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "from random import randrange, choice\r\n",
        "import pickle\r\n",
        "import nltk \r\n",
        "stopwords = nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4K39WIj14HOp"
      },
      "outputs": [],
      "source": [
        "# Carga de la data\r\n",
        "\r\n",
        "Flagged_basic = pickle.load(open(\"./data_final/Flagged_basic.p\", \"rb\" ))\r\n",
        "Flagged_GloVe = pickle.load(open(\"./data_final/Flagged_GloVe.p\", \"rb\" ))\r\n",
        "\r\n",
        "Flagged = Flagged_basic + Flagged_GloVe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_ercF86adr0",
        "outputId": "cf72ef43-2c36-4185-cbb0-c6699439132a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'i': 1, 'be': 2, 'and': 3, 'to': 4, 'she': 5, 'go': 6, 'he': 7, 'a': 8, 'have': 9, 'my': 10, 'help': 11, 'the': 12, 'with': 13, 'talk': 14, 'of': 15, 'depression': 16, 'for': 17, 'get': 18, 'in': 19, 'anxiety': 20, 'that': 21, 'try': 22, 'would': 23, 'as': 24, 'when': 25, 'it': 26, 'good': 27, 'through': 28, 'her': 29, 'but': 30, 'make': 31, 'year': 32, 'issue': 33, 'think': 34, 'deal': 35, 'life': 36, 'one': 37, 'use': 38, 'addiction': 39, 'everything': 40, 'find': 41, 'out': 42, 'some': 43, 'they': 44, 'though': 45, 'well': 46, 'back': 47, 'severe': 48, 'ex': 49, 'diagnose': 50, 'kill': 51, 'there': 52, 'not': 53, 'this': 54, 'on': 55, 'will': 56, 'need': 57, 'person': 58, 'call': 59, 'suicide': 60, 'what': 61, 'say': 62, 'simply': 63, 'support': 64, 'know': 65, 'come': 66, 'school': 67, 'comfort': 68, 'night': 69, 'see': 70, 'could': 71, 'time': 72, 'desire': 73, 'much': 74, 'want': 75, 'end': 76, 'disorder': 77, 'start': 78, 'look': 79, 'feel': 80, 'shit': 81, 'experience': 82, 'many': 83, 'like': 84, 'personal': 85, 'from': 86, 'up': 87, 'all': 88, 'girl': 89, 'do': 90, 'who': 91, 'day': 92, 'alcoholic': 93, 'alone': 94, 'anything': 95, 'always': 96, 'listen': 97, 'give': 98, 'advice': 99, 'self': 100, 'because': 101, 'stuff': 102, 'face': 103, 'about': 104, 'define': 105, 'basically': 106, 'even': 107, 'big': 108, 'so': 109, 'last': 110, 'either': 111, 'way': 112, 'his': 113, 'take': 114, 'hospital': 115, 'clean': 116, 'friend': 117, 'live': 118, 'while': 119, 'sister': 120, 'problem': 121, 'describe': 122, 'care': 123, 'happen': 124, 'before': 125, 'hold': 126, 'period': 127, 'intense': 128, 'sure': 129, 'month': 130, 'past': 131, 'grandmother': 132, 'shortly': 133, 'difficulty': 134, 'or': 135, 'himself': 136, 'tell': 137, 'still': 138, 'keep': 139, 'depressed': 140, 'share': 141, 'hope': 142, 'let': 143, 'understand': 144, 'offer': 145, 'answer': 146, 'little': 147, 'helpful': 148, 'serious': 149, 'trouble': 150, 'date': 151, 'mental': 152, 'onset': 153, 'addict': 154, 'after': 155, 'few': 156, 'other': 157, 'how': 158, 'having': 159, 'myself': 160, 'now': 161, 'at': 162, 'alcoholism': 163, 'illness': 164, 'anger': 165, 'manage': 166, 'down': 167, 'also': 168, 'hear': 169, 'very': 170, 'low': 171, 'esteem': 172, 'promise': 173, 'remind': 174, 'then': 175, 'our': 176, 'parent': 177, 'throw': 178, 'house': 179, 'part': 180, 'another': 181, 'bedroom': 182, 'similar': 183, 'treat': 184, 'human': 185, 'stranger': 186, 'respect': 187, 'kindness': 188, 'blow': 189, 'over': 190, 'more': 191, 'along': 192, 'line': 193, 'blunt': 194, 'blue': 195, 'thankgive': 196, 'boyfriend': 197, 'cut': 198, 'change': 199, 'by': 200, 'reality': 201, 'nt': 202, 'unless': 203, 'pull': 204, 'complete': 205, 'lack': 206, 'family': 207, 'cop': 208, 'already': 209, 'number': 210, 'something': 211, 'calm': 212, 'campsite': 213, 'slightly': 214, 'summer': 215, 'catch': 216, 'work': 217, 'acquaintance': 218, 'lose': 219, 'virgity': 220, 'walk': 221, 'convince': 222, 'doc': 223, 'together': 224, 'spot': 225, 'couple': 226, 'quite': 227, 'emotional': 228, 'completely': 229, 'isolate': 230, 'kid': 231, 'cuttersuicidal': 232, 'slowly': 233, 'die': 234, 'inside': 235, 'own': 236, 'hang': 237, 'rehab': 238, 'swallow': 239, 'bunch': 240, 'pill': 241, 'goal': 242, 'purpose': 243, 'sustain': 244, 'survival': 245, 'mom': 246, 'away': 247, 'ode': 248, 'grade': 249, 'harm': 250, 'knowledge': 251, 'allow': 252, 'several': 253, 'internet': 254, 'psych': 255, 'ward': 256, 'drive': 257, 'n': 258, 'mother': 259, 'eventually': 260, 'relationship': 261, 'suffer': 262, 'result': 263, 'nobody': 264, 'else': 265, 'hour': 266, 'half': 267, 'huge': 268, 'douche': 269, 'swim': 270, 'enough': 271, 'same': 272, 'long': 273, 'till': 274, 'flicker': 275, 'super': 276, 'you': 277, 'both': 278, 'save': 279, 'sway': 280, 'action': 281, 'spend': 282, 'vent': 283, 'late': 284, 'entire': 285, 'throughout': 286, 'recovery': 287, 'important': 288, 'listening': 289, 'struggle': 290, 'method': 291, 'cope': 292, 'hit': 293, 'visit': 294, 'almost': 295, 'every': 296, 'treatment': 297, 'junior': 298, 'high': 299, 'light': 300, 'tunnel': 301, 'switch': 302, 'if': 303, 'laugh': 304, 'sad': 305, 'may': 306, 'rude': 307, 'essential': 308, 'hard': 309, 'drug': 310, 'cocaine': 311, 'memorial': 312, 'anniversary': 313, 'father': 314, 'might': 315, 'around': 316, 'never': 317, 'we': 318, 'pretty': 319, 'health': 320, 'sometime': 321, 'oh': 322, 'ok': 323, 'cancer': 324, 'open': 325, 'weed': 326, 'peace': 327, 'turmoil': 328, 'people': 329, 'bit': 330, 'perfect': 331, 'roommate': 332, 'death': 333, 'loss': 334, 'commit': 335, 'early': 336, 'mind': 337, 'bring': 338, 'supportive': 339, 'focus': 340, 'situation': 341, 'subject': 342, 'drag': 343, 'due': 344, 'fact': 345, 'relate': 346, 'whenever': 347, 'y': 348, 'discomfort': 349, 'paranoia': 350, 'nervousness': 351, 'addictions': 352, 'addicted': 353, 'an': 354, 'into': 355, 'only': 356, 'during': 357, 'here': 358, 'off': 359, 'than': 360, 'once': 361, 'those': 362, 'too': 363, 'just': 364, 'themselves': 365, 'their': 366, 'can': 367, 'such': 368, 'll': 369}\n",
            " \n",
            " Cantidad de palabras diferentes: 370\n"
          ]
        }
      ],
      "source": [
        "#Se carga el tokenizador de la librería Keras y se entrena con el corpus \r\n",
        "# para generar un diccionario de cada una de las palabras con su respectiva representación numérica.\r\n",
        "\r\n",
        "tokenizer = Tokenizer() \r\n",
        "tokenizer.fit_on_texts(Flagged)\r\n",
        "word_index = tokenizer.word_index\r\n",
        "\r\n",
        "total_words = len(word_index) + 1 \r\n",
        "\r\n",
        "print(tokenizer.word_index)\r\n",
        "print(\" \\n Cantidad de palabras diferentes:\",  total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZLdwlgOex-9v"
      },
      "outputs": [],
      "source": [
        "# Creación de las secuencias de entrada de la red neuronal \r\n",
        "## con oraciones del set de datos, las cuales serán convertidas en secuencias de números \r\n",
        "## en un arreglo de estilo n-gram\r\n",
        "\r\n",
        "input_sequences = []\r\n",
        "\r\n",
        "for line in Flagged:\r\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\r\n",
        "\tfor i in range(1, len(token_list)):\r\n",
        "\t\tn_gram_sequence = token_list[:i+1]\r\n",
        "\t\tinput_sequences.append(n_gram_sequence)\r\n",
        "\r\n",
        "# Conocer la longitud máxima para igualar las cadenas a la más larga.\r\n",
        "\r\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\r\n",
        "\r\n",
        "# Completar las cadenas cortas a la más larga con el \"padding\"\r\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\r\n",
        "\r\n",
        "# Separación de objetivo y predictoras según el último término del input_sequences para \"Y\"\" y el resto para \"X\"\r\n",
        "predictors, label = input_sequences[:,:-1], input_sequences[:,-1]\r\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kWewRnDv3-lS"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(total_words, 240, input_length = max_sequence_len-1))\r\n",
        "model.add(Bidirectional(LSTM(150, return_sequences = True)))\r\n",
        "model.add(Bidirectional(LSTM(150, return_sequences = True)))\r\n",
        "model.add(LSTM(100))\r\n",
        "model.add(Dropout(0.4))\r\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\r\n",
        "model.add(Dense(total_words, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 17, 240)           88800     \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 17, 300)           469200    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 17, 300)           541200    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 185)               18685     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 370)               68820     \n",
            "=================================================================\n",
            "Total params: 1,347,105\n",
            "Trainable params: 1,347,105\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\r\n",
        "      \r\n",
        "      def on_epoch_end(self, epoch, logs={}):\r\n",
        "            if(logs.get('accuracy')> 0.85):\r\n",
        "                  print(\"\\nReached 85% accuracy so cancelling training!\")\r\n",
        "                  self.model.stop_training = True\r\n",
        "\r\n",
        "callbacks = myCallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUuz33U8ajbm",
        "outputId": "774ad2ff-11d9-4f63-db43-900152c99369",
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "165/165 [==============================] - 14s 41ms/step - loss: 6.2151 - accuracy: 0.0292\n",
            "Epoch 2/200\n",
            "165/165 [==============================] - 10s 59ms/step - loss: 5.5930 - accuracy: 0.0365\n",
            "Epoch 3/200\n",
            "165/165 [==============================] - 10s 60ms/step - loss: 5.4169 - accuracy: 0.0316\n",
            "Epoch 4/200\n",
            "165/165 [==============================] - 10s 60ms/step - loss: 5.2954 - accuracy: 0.0328\n",
            "Epoch 5/200\n",
            "165/165 [==============================] - 9s 56ms/step - loss: 5.2211 - accuracy: 0.0310\n",
            "Epoch 6/200\n",
            "165/165 [==============================] - 9s 52ms/step - loss: 5.1250 - accuracy: 0.0377\n",
            "Epoch 7/200\n",
            "165/165 [==============================] - 10s 58ms/step - loss: 5.0204 - accuracy: 0.0383\n",
            "Epoch 8/200\n",
            "165/165 [==============================] - 9s 57ms/step - loss: 4.9353 - accuracy: 0.0359\n",
            "Epoch 9/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 4.8611 - accuracy: 0.0383\n",
            "Epoch 10/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 4.7858 - accuracy: 0.0419\n",
            "Epoch 11/200\n",
            "165/165 [==============================] - 9s 56ms/step - loss: 4.7066 - accuracy: 0.0462\n",
            "Epoch 12/200\n",
            "165/165 [==============================] - 9s 52ms/step - loss: 4.6531 - accuracy: 0.0462\n",
            "Epoch 13/200\n",
            "165/165 [==============================] - 10s 58ms/step - loss: 4.5923 - accuracy: 0.0535\n",
            "Epoch 14/200\n",
            "165/165 [==============================] - 9s 54ms/step - loss: 4.5530 - accuracy: 0.0559\n",
            "Epoch 15/200\n",
            "165/165 [==============================] - 10s 60ms/step - loss: 4.5072 - accuracy: 0.0614\n",
            "Epoch 16/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 4.4351 - accuracy: 0.0675\n",
            "Epoch 17/200\n",
            "165/165 [==============================] - 9s 52ms/step - loss: 4.3672 - accuracy: 0.0748\n",
            "Epoch 18/200\n",
            "165/165 [==============================] - 9s 57ms/step - loss: 4.3349 - accuracy: 0.0760\n",
            "Epoch 19/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 4.2653 - accuracy: 0.0815\n",
            "Epoch 20/200\n",
            "165/165 [==============================] - 9s 52ms/step - loss: 4.2091 - accuracy: 0.0906\n",
            "Epoch 21/200\n",
            "165/165 [==============================] - 9s 54ms/step - loss: 4.1697 - accuracy: 0.0942\n",
            "Epoch 22/200\n",
            "165/165 [==============================] - 10s 60ms/step - loss: 4.1057 - accuracy: 0.1125\n",
            "Epoch 23/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 4.0389 - accuracy: 0.1125\n",
            "Epoch 24/200\n",
            "165/165 [==============================] - 9s 52ms/step - loss: 3.9753 - accuracy: 0.1112\n",
            "Epoch 25/200\n",
            "165/165 [==============================] - 9s 52ms/step - loss: 3.9123 - accuracy: 0.1319\n",
            "Epoch 26/200\n",
            "165/165 [==============================] - 10s 62ms/step - loss: 3.8615 - accuracy: 0.1350\n",
            "Epoch 27/200\n",
            "165/165 [==============================] - 9s 57ms/step - loss: 3.8034 - accuracy: 0.1447\n",
            "Epoch 28/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 3.7269 - accuracy: 0.1635\n",
            "Epoch 29/200\n",
            "165/165 [==============================] - 9s 52ms/step - loss: 3.7013 - accuracy: 0.1514\n",
            "Epoch 30/200\n",
            "165/165 [==============================] - 10s 62ms/step - loss: 3.6490 - accuracy: 0.1696\n",
            "Epoch 31/200\n",
            "165/165 [==============================] - 11s 64ms/step - loss: 3.5686 - accuracy: 0.1872\n",
            "Epoch 32/200\n",
            "165/165 [==============================] - 9s 52ms/step - loss: 3.5185 - accuracy: 0.1976\n",
            "Epoch 33/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 3.4502 - accuracy: 0.2109\n",
            "Epoch 34/200\n",
            "165/165 [==============================] - 9s 57ms/step - loss: 3.4162 - accuracy: 0.1964\n",
            "Epoch 35/200\n",
            "165/165 [==============================] - 10s 60ms/step - loss: 3.3503 - accuracy: 0.2201\n",
            "Epoch 36/200\n",
            "165/165 [==============================] - 9s 55ms/step - loss: 3.3026 - accuracy: 0.2304\n",
            "Epoch 37/200\n",
            "165/165 [==============================] - 9s 54ms/step - loss: 3.2323 - accuracy: 0.2511\n",
            "Epoch 38/200\n",
            "165/165 [==============================] - 9s 56ms/step - loss: 3.1546 - accuracy: 0.2650\n",
            "Epoch 39/200\n",
            "165/165 [==============================] - 9s 57ms/step - loss: 3.0751 - accuracy: 0.2894\n",
            "Epoch 40/200\n",
            "165/165 [==============================] - 9s 52ms/step - loss: 3.0479 - accuracy: 0.2936\n",
            "Epoch 41/200\n",
            "165/165 [==============================] - 8s 51ms/step - loss: 2.9753 - accuracy: 0.3173\n",
            "Epoch 42/200\n",
            "165/165 [==============================] - 8s 51ms/step - loss: 2.9281 - accuracy: 0.3210\n",
            "Epoch 43/200\n",
            "165/165 [==============================] - 9s 52ms/step - loss: 2.9070 - accuracy: 0.3289\n",
            "Epoch 44/200\n",
            "165/165 [==============================] - 9s 52ms/step - loss: 2.8620 - accuracy: 0.3362\n",
            "Epoch 45/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 2.7788 - accuracy: 0.3532\n",
            "Epoch 46/200\n",
            "165/165 [==============================] - 9s 55ms/step - loss: 2.7369 - accuracy: 0.3720\n",
            "Epoch 47/200\n",
            "165/165 [==============================] - 9s 55ms/step - loss: 2.6348 - accuracy: 0.3854\n",
            "Epoch 48/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 2.6122 - accuracy: 0.3982\n",
            "Epoch 49/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 2.5828 - accuracy: 0.4000\n",
            "Epoch 50/200\n",
            "165/165 [==============================] - 9s 52ms/step - loss: 2.5083 - accuracy: 0.4116\n",
            "Epoch 51/200\n",
            "165/165 [==============================] - 9s 54ms/step - loss: 2.4258 - accuracy: 0.4389\n",
            "Epoch 52/200\n",
            "165/165 [==============================] - 9s 52ms/step - loss: 2.3796 - accuracy: 0.4529\n",
            "Epoch 53/200\n",
            "165/165 [==============================] - 10s 60ms/step - loss: 2.3378 - accuracy: 0.4663\n",
            "Epoch 54/200\n",
            "165/165 [==============================] - 9s 56ms/step - loss: 2.2874 - accuracy: 0.4711\n",
            "Epoch 55/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 2.2606 - accuracy: 0.4675\n",
            "Epoch 56/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 2.2311 - accuracy: 0.4833\n",
            "Epoch 57/200\n",
            "165/165 [==============================] - 8s 51ms/step - loss: 2.1659 - accuracy: 0.5033\n",
            "Epoch 58/200\n",
            "165/165 [==============================] - 9s 54ms/step - loss: 2.1157 - accuracy: 0.5264\n",
            "Epoch 59/200\n",
            "165/165 [==============================] - 9s 56ms/step - loss: 2.0830 - accuracy: 0.5313\n",
            "Epoch 60/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 2.0827 - accuracy: 0.5271\n",
            "Epoch 61/200\n",
            "165/165 [==============================] - 8s 50ms/step - loss: 2.0682 - accuracy: 0.5319\n",
            "Epoch 62/200\n",
            "165/165 [==============================] - 8s 51ms/step - loss: 1.9828 - accuracy: 0.5508\n",
            "Epoch 63/200\n",
            "165/165 [==============================] - 9s 54ms/step - loss: 1.9631 - accuracy: 0.5581\n",
            "Epoch 64/200\n",
            "165/165 [==============================] - 10s 58ms/step - loss: 1.8963 - accuracy: 0.5690\n",
            "Epoch 65/200\n",
            "165/165 [==============================] - 8s 51ms/step - loss: 1.8671 - accuracy: 0.5751\n",
            "Epoch 66/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 1.8144 - accuracy: 0.5848\n",
            "Epoch 67/200\n",
            "165/165 [==============================] - 8s 50ms/step - loss: 1.8129 - accuracy: 0.5988\n",
            "Epoch 68/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 1.7684 - accuracy: 0.5982\n",
            "Epoch 69/200\n",
            "165/165 [==============================] - 9s 54ms/step - loss: 1.7673 - accuracy: 0.5976\n",
            "Epoch 70/200\n",
            "165/165 [==============================] - 10s 63ms/step - loss: 1.7243 - accuracy: 0.6158\n",
            "Epoch 71/200\n",
            "165/165 [==============================] - 12s 75ms/step - loss: 1.6572 - accuracy: 0.6359\n",
            "Epoch 72/200\n",
            "165/165 [==============================] - 9s 57ms/step - loss: 1.6746 - accuracy: 0.6292\n",
            "Epoch 73/200\n",
            "165/165 [==============================] - 10s 59ms/step - loss: 1.6203 - accuracy: 0.6450\n",
            "Epoch 74/200\n",
            "165/165 [==============================] - 10s 58ms/step - loss: 1.5927 - accuracy: 0.6450\n",
            "Epoch 75/200\n",
            "165/165 [==============================] - 9s 55ms/step - loss: 1.5642 - accuracy: 0.6632\n",
            "Epoch 76/200\n",
            "165/165 [==============================] - 9s 54ms/step - loss: 1.6207 - accuracy: 0.6474\n",
            "Epoch 77/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 1.5126 - accuracy: 0.6760\n",
            "Epoch 78/200\n",
            "165/165 [==============================] - 10s 59ms/step - loss: 1.4680 - accuracy: 0.6821\n",
            "Epoch 79/200\n",
            "165/165 [==============================] - 10s 60ms/step - loss: 1.4424 - accuracy: 0.6900\n",
            "Epoch 80/200\n",
            "165/165 [==============================] - 9s 55ms/step - loss: 1.4128 - accuracy: 0.7027\n",
            "Epoch 81/200\n",
            "165/165 [==============================] - 10s 62ms/step - loss: 1.3935 - accuracy: 0.6960\n",
            "Epoch 82/200\n",
            "165/165 [==============================] - 10s 59ms/step - loss: 1.3417 - accuracy: 0.7021\n",
            "Epoch 83/200\n",
            "165/165 [==============================] - 10s 58ms/step - loss: 1.3149 - accuracy: 0.7149\n",
            "Epoch 84/200\n",
            "165/165 [==============================] - 10s 58ms/step - loss: 1.3062 - accuracy: 0.7112\n",
            "Epoch 85/200\n",
            "165/165 [==============================] - 10s 60ms/step - loss: 1.2660 - accuracy: 0.7289\n",
            "Epoch 86/200\n",
            "165/165 [==============================] - 10s 61ms/step - loss: 1.2738 - accuracy: 0.7234\n",
            "Epoch 87/200\n",
            "165/165 [==============================] - 11s 64ms/step - loss: 1.2507 - accuracy: 0.7374\n",
            "Epoch 88/200\n",
            "165/165 [==============================] - 11s 66ms/step - loss: 1.2541 - accuracy: 0.7404\n",
            "Epoch 89/200\n",
            "165/165 [==============================] - 10s 63ms/step - loss: 1.2367 - accuracy: 0.7337\n",
            "Epoch 90/200\n",
            "165/165 [==============================] - 10s 60ms/step - loss: 1.2159 - accuracy: 0.7404\n",
            "Epoch 91/200\n",
            "165/165 [==============================] - 9s 57ms/step - loss: 1.1468 - accuracy: 0.7647\n",
            "Epoch 92/200\n",
            "165/165 [==============================] - 9s 57ms/step - loss: 1.1606 - accuracy: 0.7617\n",
            "Epoch 93/200\n",
            "165/165 [==============================] - 10s 61ms/step - loss: 1.1399 - accuracy: 0.7623\n",
            "Epoch 94/200\n",
            "165/165 [==============================] - 10s 62ms/step - loss: 1.1907 - accuracy: 0.7526\n",
            "Epoch 95/200\n",
            "165/165 [==============================] - 10s 64ms/step - loss: 1.1625 - accuracy: 0.7422\n",
            "Epoch 96/200\n",
            "165/165 [==============================] - 11s 69ms/step - loss: 1.0826 - accuracy: 0.7751\n",
            "Epoch 97/200\n",
            "165/165 [==============================] - 11s 68ms/step - loss: 1.0810 - accuracy: 0.7824\n",
            "Epoch 98/200\n",
            "165/165 [==============================] - 11s 64ms/step - loss: 1.0475 - accuracy: 0.7970\n",
            "Epoch 99/200\n",
            "165/165 [==============================] - 11s 69ms/step - loss: 1.0438 - accuracy: 0.7848\n",
            "Epoch 100/200\n",
            "165/165 [==============================] - 9s 56ms/step - loss: 1.0022 - accuracy: 0.7915\n",
            "Epoch 101/200\n",
            "165/165 [==============================] - 9s 54ms/step - loss: 1.0041 - accuracy: 0.8006\n",
            "Epoch 102/200\n",
            "165/165 [==============================] - 9s 54ms/step - loss: 0.9896 - accuracy: 0.7988\n",
            "Epoch 103/200\n",
            "165/165 [==============================] - 9s 54ms/step - loss: 0.9704 - accuracy: 0.8073\n",
            "Epoch 104/200\n",
            "165/165 [==============================] - 9s 54ms/step - loss: 0.9931 - accuracy: 0.7824\n",
            "Epoch 105/200\n",
            "165/165 [==============================] - 9s 54ms/step - loss: 0.9699 - accuracy: 0.7951\n",
            "Epoch 106/200\n",
            "165/165 [==============================] - 10s 62ms/step - loss: 0.9296 - accuracy: 0.8182\n",
            "Epoch 107/200\n",
            "165/165 [==============================] - 10s 61ms/step - loss: 0.9374 - accuracy: 0.8091\n",
            "Epoch 108/200\n",
            "165/165 [==============================] - 10s 63ms/step - loss: 0.9210 - accuracy: 0.8091\n",
            "Epoch 109/200\n",
            "165/165 [==============================] - 9s 57ms/step - loss: 0.9160 - accuracy: 0.8170\n",
            "Epoch 110/200\n",
            "165/165 [==============================] - 9s 55ms/step - loss: 0.8975 - accuracy: 0.8158\n",
            "Epoch 111/200\n",
            "165/165 [==============================] - 9s 54ms/step - loss: 0.8998 - accuracy: 0.8237\n",
            "Epoch 112/200\n",
            "165/165 [==============================] - 9s 54ms/step - loss: 0.9055 - accuracy: 0.8103\n",
            "Epoch 113/200\n",
            "165/165 [==============================] - 10s 58ms/step - loss: 0.9821 - accuracy: 0.7994\n",
            "Epoch 114/200\n",
            "165/165 [==============================] - 10s 58ms/step - loss: 0.9076 - accuracy: 0.8036\n",
            "Epoch 115/200\n",
            "165/165 [==============================] - 9s 55ms/step - loss: 0.8752 - accuracy: 0.8237\n",
            "Epoch 116/200\n",
            "165/165 [==============================] - 9s 56ms/step - loss: 0.8446 - accuracy: 0.8304\n",
            "Epoch 117/200\n",
            "165/165 [==============================] - 9s 57ms/step - loss: 0.8236 - accuracy: 0.8310\n",
            "Epoch 118/200\n",
            "165/165 [==============================] - 10s 61ms/step - loss: 0.8274 - accuracy: 0.8298\n",
            "Epoch 119/200\n",
            "165/165 [==============================] - 10s 60ms/step - loss: 0.8024 - accuracy: 0.8377\n",
            "Epoch 120/200\n",
            "165/165 [==============================] - 9s 53ms/step - loss: 0.7789 - accuracy: 0.8389\n",
            "Epoch 121/200\n",
            "165/165 [==============================] - 9s 57ms/step - loss: 0.7640 - accuracy: 0.8413\n",
            "Epoch 122/200\n",
            "165/165 [==============================] - 9s 57ms/step - loss: 0.7850 - accuracy: 0.8395\n",
            "Epoch 123/200\n",
            "165/165 [==============================] - 10s 62ms/step - loss: 0.7820 - accuracy: 0.8334\n",
            "Epoch 124/200\n",
            "165/165 [==============================] - 10s 58ms/step - loss: 0.8204 - accuracy: 0.8304\n",
            "Epoch 125/200\n",
            "165/165 [==============================] - 9s 58ms/step - loss: 0.7986 - accuracy: 0.8371\n",
            "Epoch 126/200\n",
            "165/165 [==============================] - 9s 54ms/step - loss: 0.7688 - accuracy: 0.8535\n",
            "\n",
            "Reached 85% accuracy so cancelling training!\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(predictors, label, batch_size=10, epochs=200, verbose=1, callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "8rLBQLSa4kdq",
        "outputId": "5f933c56-e511-4c5c-8e3c-ba3ef80eb0d1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "epochs = range(len(acc))\n",
        "\n",
        "#grafica #2\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "plt.figure()\n",
        "\n",
        "#grafica #1\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI_1wMXwbtfk",
        "outputId": "caf45ab4-7655-4410-da53-675acc1ee5f2"
      },
      "outputs": [],
      "source": [
        "# Creación de una bolsa de palabras para elegir dos términos de manera aleatoria \r\n",
        "## que permitan dar inicio a las cadenas de texto.\r\n",
        "\r\n",
        "word_list = [key for key in word_index.keys() if key not in stopwords]\r\n",
        "\r\n",
        "# Creación de las variables que nos permitirán escoger al azar un numero \r\n",
        "## según una distribución probabilística normal\r\n",
        "mess_range = 500 - len(Flagged)\r\n",
        "mu, sigma = 8, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generación de las nuevas cadenas a partir de la secuencia de terminos anterior.\r\n",
        "\r\n",
        "LSTM_temp = []\r\n",
        "\r\n",
        "for _ in range(mess_range):\r\n",
        "  text = \"\"\r\n",
        "  text = choice(word_list) # Elección de número aleatorio de longitud\r\n",
        "  text = text + ' ' + choice(word_list)\r\n",
        "  words_qt =  int(random.gauss(mu, sigma))\r\n",
        "\r\n",
        "  for _ in range(words_qt):\r\n",
        "    token_list = tokenizer.texts_to_sequences([text])[0] #conversión del texto inicial en secuencia.\r\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')  \r\n",
        "    predicted = np.argmax(model.predict(token_list), axis=-1) #predicción a partir de la entrada transformada de los tokens\r\n",
        "    output_word = \"\"\r\n",
        "    for word, index in tokenizer.word_index.items():\r\n",
        "      if index == predicted:\r\n",
        "        output_word = word\r\n",
        "        break\r\n",
        "    text += \" \" + output_word\r\n",
        "  LSTM_temp.append(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['calm find kindness of her personal problem cope focus',\n",
              " 'reality life loss of girl get catch bedroom slowly die',\n",
              " 'suffer parent get last mental health father give support my experience',\n",
              " 'human trouble start date feel the relationship start suffer quite',\n",
              " 'look drive light lack support family hospital number know',\n",
              " 'hold way simply talk would try change it be',\n",
              " 'throughout big addiction issue i some a hospital',\n",
              " 'several half be one support result quite severe a',\n",
              " 'problem else have her mental switch on my',\n",
              " 'sometime use hear due early mind from year early good',\n",
              " 'part douche would like would have depression make in',\n",
              " 'high die inside mind kindness go through depression and',\n",
              " 'drug last past switch on want year',\n",
              " 'cop anything get bedroom all need sometime like',\n",
              " 'catch anniversary weed pill talk would answer even though']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LSTM_temp[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "W_r6bGHfmdX9"
      },
      "outputs": [],
      "source": [
        "pickle.dump(LSTM_temp, open(\"./data_final/Flagged_LSTM.p\", \"wb\" ))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TFM - Aumento de Data_Flagged.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "2d8c4e0adecca2f9bb6152916de834ccf75a0d1de20f0239611dabd3480e2716"
    },
    "kernelspec": {
      "display_name": "Python 3.9.4 64-bit",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "metadata": {
      "interpreter": {
        "hash": "2d8c4e0adecca2f9bb6152916de834ccf75a0d1de20f0239611dabd3480e2716"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}