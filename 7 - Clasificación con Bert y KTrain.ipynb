{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Carga de Librerías, datos y funciones:\r\n",
        "\r\n",
        "Fuente: \r\n",
        "https://kgptalkie.com/sentiment-classification-using-bert/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G8MVUbH6YsLd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ktrain in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.26.3)\n",
            "Requirement already satisfied: transformers<=4.3.3,>=4.0.0 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (4.3.3)\n",
            "Requirement already satisfied: whoosh in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (2.7.4)\n",
            "Requirement already satisfied: seqeval==0.0.19 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (0.0.19)\n",
            "Requirement already satisfied: cchardet in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (2.1.7)\n",
            "Requirement already satisfied: sentencepiece in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (0.1.95)\n",
            "Requirement already satisfied: requests in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (2.25.1)\n",
            "Requirement already satisfied: ipython in c:\\users\\aanun\\appdata\\roaming\\python\\python39\\site-packages (from ktrain) (7.21.0)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (3.4.1)\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (0.23.2)\n",
            "Requirement already satisfied: syntok in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (1.3.1)\n",
            "Requirement already satisfied: joblib in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (1.0.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (20.9)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (1.0.0)\n",
            "Requirement already satisfied: networkx>=2.3 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (2.5.1)\n",
            "Requirement already satisfied: langdetect in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (1.0.9)\n",
            "Requirement already satisfied: keras-bert>=0.86.0 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (0.86.0)\n",
            "Requirement already satisfied: jieba in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ktrain) (1.2.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn==0.23.2->ktrain) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn==0.23.2->ktrain) (1.6.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn==0.23.2->ktrain) (2.1.0)\n",
            "Requirement already satisfied: Keras>=2.2.4 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seqeval==0.0.19->ktrain) (2.4.3)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Keras>=2.2.4->seqeval==0.0.19->ktrain) (5.4.1)\n",
            "Requirement already satisfied: h5py in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Keras>=2.2.4->seqeval==0.0.19->ktrain) (3.1.0)\n",
            "Requirement already satisfied: keras-transformer>=0.38.0 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras-bert>=0.86.0->ktrain) (0.38.0)\n",
            "Requirement already satisfied: keras-layer-normalization>=0.14.0 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.14.0)\n",
            "Requirement already satisfied: keras-embed-sim>=0.8.0 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.8.0)\n",
            "Requirement already satisfied: keras-pos-embd>=0.11.0 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward>=0.6.0 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.6.0)\n",
            "Requirement already satisfied: keras-multi-head>=0.27.0 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.27.0)\n",
            "Requirement already satisfied: keras-self-attention==0.46.0 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras-multi-head>=0.27.0->keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (1.3.1)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (8.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\aanun\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: six in c:\\users\\aanun\\appdata\\roaming\\python\\python39\\site-packages (from cycler>=0.10->matplotlib>=3.0.0->ktrain) (1.15.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in c:\\users\\aanun\\appdata\\roaming\\python\\python39\\site-packages (from networkx>=2.3->ktrain) (4.4.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.1->ktrain) (2021.1)\n",
            "Requirement already satisfied: sacremoses in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (2020.11.13)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (4.49.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (0.10.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\aanun\\appdata\\roaming\\python\\python39\\site-packages (from ipython->ktrain) (0.4.4)\n",
            "Requirement already satisfied: traitlets>=4.2 in c:\\users\\aanun\\appdata\\roaming\\python\\python39\\site-packages (from ipython->ktrain) (5.0.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\aanun\\appdata\\roaming\\python\\python39\\site-packages (from ipython->ktrain) (3.0.16)\n",
            "Requirement already satisfied: backcall in c:\\users\\aanun\\appdata\\roaming\\python\\python39\\site-packages (from ipython->ktrain) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython->ktrain) (49.2.1)\n",
            "Requirement already satisfied: pickleshare in c:\\users\\aanun\\appdata\\roaming\\python\\python39\\site-packages (from ipython->ktrain) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\aanun\\appdata\\roaming\\python\\python39\\site-packages (from ipython->ktrain) (0.18.0)\n",
            "Requirement already satisfied: pygments in c:\\users\\aanun\\appdata\\roaming\\python\\python39\\site-packages (from ipython->ktrain) (2.8.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\aanun\\appdata\\roaming\\python\\python39\\site-packages (from jedi>=0.16->ipython->ktrain) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\aanun\\appdata\\roaming\\python\\python39\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ktrain) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in c:\\users\\aanun\\appdata\\roaming\\python\\python39\\site-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->ktrain) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->ktrain) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->ktrain) (1.26.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->ktrain) (2020.12.5)\n",
            "Requirement already satisfied: click in c:\\users\\aanun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sacremoses->transformers<=4.3.3,>=4.0.0->ktrain) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "#!pip install ktrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h8fYuy7GYvRT"
      },
      "outputs": [],
      "source": [
        "import pickle\r\n",
        "import tensorflow as tf\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import ktrain\r\n",
        "from ktrain import text\r\n",
        "import tensorflow as tf\r\n",
        "import re\r\n",
        "import string\r\n",
        "import spacy\r\n",
        "\r\n",
        "from string import digits\r\n",
        "\r\n",
        "sp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cut_text_len(list):\r\n",
        "    temp = []\r\n",
        "    temp_coma = []\r\n",
        "    temp_list = []\r\n",
        "\r\n",
        "    for sentence in list: temp.extend(sentence.split('.'))\r\n",
        "    for sentence in temp: temp_coma.extend(sentence.split(','))\r\n",
        "    temp_coma = [sentence for sentence in temp_coma if len(sentence.split()) > 2]\r\n",
        "\r\n",
        "    for sentence in temp_coma:\r\n",
        "        text = sentence.split()\r\n",
        "        new_sentence = ''\r\n",
        "        len_sentence = 0\r\n",
        "        mess = len(text)\r\n",
        "        while mess > 0:\r\n",
        "            new_sentence += text[0] + ' '\r\n",
        "            text.pop(0)\r\n",
        "            len_sentence += 1\r\n",
        "            mess = len(text)\r\n",
        "            if len_sentence == 15:            \r\n",
        "                temp_list.append(new_sentence)\r\n",
        "                new_sentence = ''\r\n",
        "                len_sentence = 0\r\n",
        "                mess = len(text)\r\n",
        "            elif mess == 0:\r\n",
        "                mess = len(new_sentence.split())\r\n",
        "                if mess <= 2:\r\n",
        "                    break\r\n",
        "                temp_list.append(new_sentence)\r\n",
        "                break\r\n",
        "    return(temp_list)\r\n",
        "\r\n",
        "def clean_text(list):   \r\n",
        "    text_clean = []\r\n",
        "    for text in list:\r\n",
        "        text = text.lower()\r\n",
        "        new_text = ''\r\n",
        "        for word in text.split():\r\n",
        "            for key in contractions:\r\n",
        "                if word == key:\r\n",
        "                    word = contractions[key]\r\n",
        "            new_text += word + ' '\r\n",
        "        text = re.sub(r'([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)', '', new_text) \r\n",
        "        text = re.sub(patron_web, '', text)\r\n",
        "        table = str.maketrans(' ', ' ', string.punctuation)\r\n",
        "        stripped = [word.translate(table) for word in text]\r\n",
        "        text = ''.join(stripped)\r\n",
        "        table = str.maketrans('', '', digits)\r\n",
        "        newtext = text.translate(table)\r\n",
        "        newtext = re.sub(\"\\'\", '', newtext)\r\n",
        "        text_clean.append(newtext)\r\n",
        "\r\n",
        "    return(text_clean)\r\n",
        "\r\n",
        "# Fuente: https://kgptalkie.com/3664-2/\r\n",
        "# Lista de contracciones en inglés extraída de \"NLP: End to End Text Processing for Beginners\" (., Roshan)\r\n",
        "\r\n",
        "contractions = { \r\n",
        "\"ain't\": \"am not\",\r\n",
        "\"aren't\": \"are not\",\r\n",
        "\"can't\": \"cannot\",\r\n",
        "\"can't've\": \"cannot have\",\r\n",
        "\"'cause\": \"because\",\r\n",
        "\"could've\": \"could have\",\r\n",
        "\"couldn't\": \"could not\",\r\n",
        "\"couldn't've\": \"could not have\",\r\n",
        "\"didn't\": \"did not\",\r\n",
        "\"doesn't\": \"does not\",\r\n",
        "\"don't\": \"do not\",\r\n",
        "\"hadn't\": \"had not\",\r\n",
        "\"hadn't've\": \"had not have\",\r\n",
        "\"hasn't\": \"has not\",\r\n",
        "\"haven't\": \"have not\",\r\n",
        "\"he'd\": \"he would\",\r\n",
        "\"he'd've\": \"he would have\",\r\n",
        "\"he'll\": \"he will\",\r\n",
        "\"he'll've\": \"he will have\",\r\n",
        "\"he's\": \"he is\",\r\n",
        "\"how'd\": \"how did\",\r\n",
        "\"how'd'y\": \"how do you\",\r\n",
        "\"how'll\": \"how will\",\r\n",
        "\"how's\": \"how does\",\r\n",
        "\"i'd\": \"i would\",\r\n",
        "\"i'd've\": \"i would have\",\r\n",
        "\"i'll\": \"i will\",\r\n",
        "\"i'll've\": \"i will have\",\r\n",
        "\"i'm\": \"i am\",\r\n",
        "\"i've\": \"i have\",\r\n",
        "\"isn't\": \"is not\",\r\n",
        "\"it'd\": \"it would\",\r\n",
        "\"it'd've\": \"it would have\",\r\n",
        "\"it'll\": \"it will\",\r\n",
        "\"it'll've\": \"it will have\",\r\n",
        "\"it's\": \"it is\",\r\n",
        "\"let's\": \"let us\",\r\n",
        "\"ma'am\": \"madam\",\r\n",
        "\"mayn't\": \"may not\",\r\n",
        "\"might've\": \"might have\",\r\n",
        "\"mightn't\": \"might not\",\r\n",
        "\"mightn't've\": \"might not have\",\r\n",
        "\"must've\": \"must have\",\r\n",
        "\"mustn't\": \"must not\",\r\n",
        "\"mustn't've\": \"must not have\",\r\n",
        "\"needn't\": \"need not\",\r\n",
        "\"needn't've\": \"need not have\",\r\n",
        "\"o'clock\": \"of the clock\",\r\n",
        "\"oughtn't\": \"ought not\",\r\n",
        "\"oughtn't've\": \"ought not have\",\r\n",
        "\"shan't\": \"shall not\",\r\n",
        "\"sha'n't\": \"shall not\",\r\n",
        "\"shan't've\": \"shall not have\",\r\n",
        "\"she'd\": \"she would\",\r\n",
        "\"she'd've\": \"she would have\",\r\n",
        "\"she'll\": \"she will\",\r\n",
        "\"she'll've\": \"she will have\",\r\n",
        "\"she's\": \"she is\",\r\n",
        "\"should've\": \"should have\",\r\n",
        "\"shouldn't\": \"should not\",\r\n",
        "\"shouldn't've\": \"should not have\",\r\n",
        "\"so've\": \"so have\",\r\n",
        "\"so's\": \"so is\",\r\n",
        "\"that'd\": \"that would\",\r\n",
        "\"that'd've\": \"that would have\",\r\n",
        "\"that's\": \"that is\",\r\n",
        "\"there'd\": \"there would\",\r\n",
        "\"there'd've\": \"there would have\",\r\n",
        "\"there's\": \"there is\",\r\n",
        "\"they'd\": \"they would\",\r\n",
        "\"they'd've\": \"they would have\",\r\n",
        "\"they'll\": \"they will\",\r\n",
        "\"they'll've\": \"they will have\",\r\n",
        "\"they're\": \"they are\",\r\n",
        "\"they've\": \"they have\",\r\n",
        "\"to've\": \"to have\",\r\n",
        "\"wasn't\": \"was not\",\r\n",
        "\"aint\": \"am not\",\r\n",
        "\"arent\": \"are not\",\r\n",
        "\"cant\": \"can not\",\r\n",
        "\"cantve\": \"cannot have\",\r\n",
        "\"cause\": \"because\",\r\n",
        "\"couldve\": \"could have\",\r\n",
        "\"couldnt\": \"could not\",\r\n",
        "\"couldntve\": \"could not have\",\r\n",
        "\"didnt\": \"did not\",\r\n",
        "\"doesnt\": \"does not\",\r\n",
        "\"dont\": \"do not\",\r\n",
        "\"hadnt\": \"had not\",\r\n",
        "\"hadntve\": \"had not have\",\r\n",
        "\"hasnt\": \"has not\",\r\n",
        "\"havent\": \"have not\",\r\n",
        "\"hed\": \"he would\",\r\n",
        "\"hedve\": \"he would have\",\r\n",
        "\"hell\": \"he will\",\r\n",
        "\"hellve\": \"he will have\",\r\n",
        "\"hes\": \"he is\",\r\n",
        "\"howd\": \"how did\",\r\n",
        "\"howdy\": \"how do you\",\r\n",
        "\"howll\": \"how will\",\r\n",
        "\"hows\": \"how does\",\r\n",
        "\"id\": \"i would\",\r\n",
        "\"idve\": \"i would have\",\r\n",
        "\"ill\": \"i will\",\r\n",
        "\"illve\": \"i will have\",\r\n",
        "\"im\": \"i am\",\r\n",
        "\"ive\": \"i have\",\r\n",
        "\"isnt\": \"is not\",\r\n",
        "\"itd\": \"it would\",\r\n",
        "\"itdve\": \"it would have\",\r\n",
        "\"itll\": \"it will\",\r\n",
        "\"itllve\": \"it will have\",\r\n",
        "\"its\": \"it is\",\r\n",
        "\"lets\": \"let us\",\r\n",
        "\"maam\": \"madam\",\r\n",
        "\"maynt\": \"may not\",\r\n",
        "\"mightve\": \"might have\",\r\n",
        "\"mightnt\": \"might not\",\r\n",
        "\"mightntve\": \"might not have\",\r\n",
        "\"mustve\": \"must have\",\r\n",
        "\"mustnt\": \"must not\",\r\n",
        "\"mustntve\": \"must not have\",\r\n",
        "\"neednt\": \"need not\",\r\n",
        "\"needntve\": \"need not have\",\r\n",
        "\"oclock\": \"of the clock\",\r\n",
        "\"oughtnt\": \"ought not\",\r\n",
        "\"oughtntve\": \"ought not have\",\r\n",
        "\"shant\": \"shall not\",\r\n",
        "\"shant\": \"shall not\",\r\n",
        "\"shantve\": \"shall not have\",\r\n",
        "\"shed\": \"she would\",\r\n",
        "\"shedve\": \"she would have\",\r\n",
        "\"shell\": \"she will\",\r\n",
        "\"shellve\": \"she will have\",\r\n",
        "\"shes\": \"she is\",\r\n",
        "\"shouldve\": \"should have\",\r\n",
        "\"shouldnt\": \"should not\",\r\n",
        "\"shouldntve\": \"should not have\",\r\n",
        "\"sove\": \"so have\",\r\n",
        "\"sos\": \"so is\",\r\n",
        "\"thatd\": \"that would\",\r\n",
        "\"thatdve\": \"that would have\",\r\n",
        "\"thats\": \"that is\",\r\n",
        "\"thered\": \"there would\",\r\n",
        "\"theredve\": \"there would have\",\r\n",
        "\"theres\": \"there is\",\r\n",
        "\"theyd\": \"they would\",\r\n",
        "\"theydve\": \"they would have\",\r\n",
        "\"theyll\": \"they will\",\r\n",
        "\"theyllve\": \"they will have\",\r\n",
        "\"theyre\": \"they are\",\r\n",
        "\"theyve\": \"they have\",\r\n",
        "\"tove\": \"to have\",\r\n",
        "\"wasnt\": \"was not\", \r\n",
        "\"u\": \" you  \",\r\n",
        "\"ur\": \"your\", \r\n",
        "\"n\": \"and\", \r\n",
        "\"friends\": \"\",\r\n",
        "\"friend\":\"\",\r\n",
        "\"people\":\"\",\r\n",
        "\"girl\":\"\",\r\n",
        "\"girlfriend\": \"\",\r\n",
        "\"grl\":\"\",\r\n",
        "\"nt\": \"not\",\r\n",
        "\"gf\": \"\", \r\n",
        "\"cuttersuicidal\": \"suicidal\", \r\n",
        "\"idk\": \"i do not know\", \r\n",
        "\"theripist\": \"therapist\",\r\n",
        "\"s\": \"is\",\r\n",
        "\"mt\": \"\",\r\n",
        "\"cuttersuicidal\": \"cutter suicidal\"\r\n",
        "}\r\n",
        "\r\n",
        "patron_web = r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?'\r\n",
        "\r\n",
        "def duplicated(list): \r\n",
        "    temp = []\r\n",
        "    for sentence in list:\r\n",
        "        new_sentence = sentence.split() \r\n",
        "        new_sentece_join = ' '.join(new_sentence)\r\n",
        "        temp.append(new_sentece_join)\r\n",
        "    return(temp)\r\n",
        "\r\n",
        "def text_to_spacy(list): \r\n",
        "    temp = []\r\n",
        "    for sentence in list:\r\n",
        "        new_sentence = ''\r\n",
        "        for word in sp(str(sentence)):\r\n",
        "            new_sentence += word.lemma_ + ' '\r\n",
        "        temp.append(new_sentence.lower())\r\n",
        "    return(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3RYRjnY3YwGA"
      },
      "outputs": [],
      "source": [
        "\r\n",
        "df = pickle.load(open(\"./data/df.p\", \"rb\" ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "26tk78nVpQRZ",
        "outputId": "201eed84-2576-4ebb-bd4a-20434fef1ffb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>label_bi</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>651</th>\n",
              "      <td>ex have onset and anxiety</td>\n",
              "      <td>flagged</td>\n",
              "      <td>1</td>\n",
              "      <td>-909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>dumps expressing one schoolwork so think my li...</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>0</td>\n",
              "      <td>-903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>that need it be a fairly common occurrence</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>0</td>\n",
              "      <td>-837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736</th>\n",
              "      <td>i call back and get a hospital number so i kno...</td>\n",
              "      <td>flagged</td>\n",
              "      <td>1</td>\n",
              "      <td>-833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>gave least went campingsurfing week work throu...</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>0</td>\n",
              "      <td>-783</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text        label  label_bi  \\\n",
              "651                          ex have onset and anxiety      flagged         1   \n",
              "108  dumps expressing one schoolwork so think my li...  not_flagged         0   \n",
              "441         that need it be a fairly common occurrence  not_flagged         0   \n",
              "736  i call back and get a hospital number so i kno...      flagged         1   \n",
              "145  gave least went campingsurfing week work throu...  not_flagged         0   \n",
              "\n",
              "     index  \n",
              "651   -909  \n",
              "108   -903  \n",
              "441   -837  \n",
              "736   -833  \n",
              "145   -783  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EH8icEy9oA2G"
      },
      "outputs": [],
      "source": [
        "msk = np.random.rand(len(df)) < 0.8\n",
        "train = df[msk]\n",
        "test = df[~msk]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLE2qTwYoCV9",
        "outputId": "b105ac6e-f597-40b2-d0ad-4df89afe2ee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of train dataset:  (822, 4)\n",
            "Size of test dataset:  (186, 4)\n"
          ]
        }
      ],
      "source": [
        "print(\"Size of train dataset: \", train.shape)\n",
        "print(\"Size of test dataset: \", test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "1UL-6b_6sF0z",
        "outputId": "da437cf0-d117-48f7-a46d-a923d877d703"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>label_bi</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>651</th>\n",
              "      <td>ex have onset and anxiety</td>\n",
              "      <td>flagged</td>\n",
              "      <td>1</td>\n",
              "      <td>-909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>dumps expressing one schoolwork so think my li...</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>0</td>\n",
              "      <td>-903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736</th>\n",
              "      <td>i call back and get a hospital number so i kno...</td>\n",
              "      <td>flagged</td>\n",
              "      <td>1</td>\n",
              "      <td>-833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>gave least went campingsurfing week work throu...</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>0</td>\n",
              "      <td>-783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>others even truth hurts best way start even would</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>0</td>\n",
              "      <td>-758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>i try to be there for she when she need it and...</td>\n",
              "      <td>flagged</td>\n",
              "      <td>1</td>\n",
              "      <td>885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>try kind helpful honest</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>0</td>\n",
              "      <td>897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760</th>\n",
              "      <td>issue suicide every day grade kindness of a ho...</td>\n",
              "      <td>flagged</td>\n",
              "      <td>1</td>\n",
              "      <td>948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>people person he be not the throughout to</td>\n",
              "      <td>flagged</td>\n",
              "      <td>1</td>\n",
              "      <td>976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>took week work</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>0</td>\n",
              "      <td>1030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>822 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text        label  label_bi  \\\n",
              "651                          ex have onset and anxiety      flagged         1   \n",
              "108  dumps expressing one schoolwork so think my li...  not_flagged         0   \n",
              "736  i call back and get a hospital number so i kno...      flagged         1   \n",
              "145  gave least went campingsurfing week work throu...  not_flagged         0   \n",
              "321  others even truth hurts best way start even would  not_flagged         0   \n",
              "..                                                 ...          ...       ...   \n",
              "751  i try to be there for she when she need it and...      flagged         1   \n",
              "482                            try kind helpful honest  not_flagged         0   \n",
              "760  issue suicide every day grade kindness of a ho...      flagged         1   \n",
              "860          people person he be not the throughout to      flagged         1   \n",
              "470                                     took week work  not_flagged         0   \n",
              "\n",
              "     index  \n",
              "651   -909  \n",
              "108   -903  \n",
              "736   -833  \n",
              "145   -783  \n",
              "321   -758  \n",
              "..     ...  \n",
              "751    885  \n",
              "482    897  \n",
              "760    948  \n",
              "860    976  \n",
              "470   1030  \n",
              "\n",
              "[822 rows x 4 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preparación de la data y modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "vWuJFMEuoyNd",
        "outputId": "83a84d0e-5f68-456a-820a-3a23fbc57c09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['flagged', 'not_flagged']\n",
            "     flagged  not_flagged\n",
            "651      1.0          0.0\n",
            "108      0.0          1.0\n",
            "736      1.0          0.0\n",
            "145      0.0          1.0\n",
            "321      0.0          1.0\n",
            "['flagged', 'not_flagged']\n",
            "     flagged  not_flagged\n",
            "441      0.0          1.0\n",
            "451      0.0          1.0\n",
            "753      1.0          0.0\n",
            "78       0.0          1.0\n",
            "550      1.0          0.0\n",
            "preprocessing train...\n",
            "language: en\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# El framework de K-train tiene un método para la separación de las cadenas \r\n",
        "## la función que preprocesará la data.\r\n",
        "\r\n",
        "(X_train, y_train), (X_test, y_test), preproc = text.texts_from_df(train_df= train,\r\n",
        "                                                                   text_column = 'text',\r\n",
        "                                                                   label_columns = 'label',\r\n",
        "                                                                   val_df = test,\r\n",
        "                                                                   maxlen = 16,\r\n",
        "                                                                   preprocess_mode = 'bert')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfTjYwUtsLV1",
        "outputId": "76a50b02-3bb6-4c5b-e543-297cab471b4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(822, 16)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNi2yKxNpBfU",
        "outputId": "e0e9406c-5f06-4f9b-bf84-d9f1217daf71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 16\n",
            "done.\n"
          ]
        }
      ],
      "source": [
        "# Creación del modelo\r\n",
        "\r\n",
        "model = text.text_classifier(name = 'bert',\r\n",
        "                             train_data = (X_train, y_train),\r\n",
        "                             preproc = preproc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EqrZJjYMpKiU"
      },
      "outputs": [],
      "source": [
        "# Compilación del modelo\r\n",
        "\r\n",
        "learner = ktrain.get_learner(model=model, train_data=(X_train, y_train),\r\n",
        "                   val_data = (X_test, y_test),\r\n",
        "                   batch_size = 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEEVQ-tiqWru",
        "outputId": "7dbcfb1d-0aed-48dd-99cb-d6a40d908fcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "Epoch 1/5\n",
            "137/137 [==============================] - 201s 1s/step - loss: 0.6971 - accuracy: 0.5864 - val_loss: 0.6238 - val_accuracy: 0.6774\n",
            "Epoch 2/5\n",
            "137/137 [==============================] - 164s 1s/step - loss: 0.4323 - accuracy: 0.8078 - val_loss: 0.3627 - val_accuracy: 0.8441\n",
            "Epoch 3/5\n",
            "137/137 [==============================] - 161s 1s/step - loss: 0.1569 - accuracy: 0.9331 - val_loss: 0.3521 - val_accuracy: 0.9086\n",
            "Epoch 4/5\n",
            "137/137 [==============================] - 173s 1s/step - loss: 0.0268 - accuracy: 0.9927 - val_loss: 0.3573 - val_accuracy: 0.9032\n",
            "Epoch 5/5\n",
            "137/137 [==============================] - 156s 1s/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 0.3412 - val_accuracy: 0.9247\n"
          ]
        }
      ],
      "source": [
        "#Proceso de entrenamiento\r\n",
        "\r\n",
        "learner.fit_onecycle(lr = 2e-5, epochs = 5)\r\n",
        "predictor = ktrain.get_predictor(learner.model, preproc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5VjFW0Liq-0g"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejemplo #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Xr7fMGYfxXo_"
      },
      "outputs": [],
      "source": [
        "new_sentences = [\"I've some anxiety and some days want to die\", \r\n",
        "                        \"I help her with her depression\",\r\n",
        "                        \"I'm very sad and depressed today. want to finish it \", \r\n",
        "                        \"Some of my friends are suicidal\", \r\n",
        "                        \"I am happy and joyful \"]\r\n",
        "                        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIzkUFLWxh8X",
        "outputId": "115da627-ed65-4547-c7b3-7844bae07079"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['flagged', 'flagged', 'not_flagged', 'flagged', 'not_flagged']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(new_sentences)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_sentences = cut_text_len(new_sentences)\r\n",
        "new_sentences = clean_text(new_sentences)\r\n",
        "new_sentences = text_to_spacy(new_sentences)\r\n",
        "new_sentences = duplicated(new_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['flagged', 'flagged', 'flagged', 'flagged', 'flagged', 'flagged']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(new_sentences)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejemplo #2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "\r\n",
        "new_sentences = [\"my name is andie. i am 16 years old. my life is too messed up for fixing. i have been through a lot. i think it's my time to go. there's no other way . i will not be stating my method because i don't want to be copied. i love you, stranger, please live a better life than me.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_sentences = cut_text_len(new_sentences)\r\n",
        "new_sentences = clean_text(new_sentences)\r\n",
        "new_sentences = text_to_spacy(new_sentences)\r\n",
        "new_sentences = duplicated(new_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['not_flagged']"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(sentences_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "my name be andie : flagged\n",
            "i be year old : not_flagged\n",
            "my life be too mess up for fix : not_flagged\n",
            "i have be through a lot : not_flagged\n",
            "i think it be my time to go : not_flagged\n",
            "there be no other way : not_flagged\n",
            "i will not be state my method because i do not want to be copy : not_flagged\n",
            "i love you : flagged\n",
            "please live a well life than i : flagged\n"
          ]
        }
      ],
      "source": [
        "i = 0\r\n",
        "for sentence in new_sentences: \r\n",
        "    print(sentence , ':',  str(total[i]))\r\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejemplo #3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_sentences = [\"Can someone explain to me how actively looking for help is one of the loneliest experiences someone can have? Not only am I miserable because I'm sick, but then I also have to listen to these people who are supposed to help me that I have to want to get better or it won't work. Now, I grew up evangelical (not practicing, agnostic, forever put off by religion) and I sure as hell know that expression. What if I don't believe in getting better. What if a big part of me just wants to decay. What if I dragged myself to your office with the last bit of strength in my body. If it were for me, I'd just lie down and die. Deep down, I don't want to get better, I want a do over. Everything is fucked. There's no ladder out of this hole, I only have a shovel and I'm going to dig myself a grave.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['not_flagged']"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict(new_sentences)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "TFM -- clasificación de sentimiento con Bert y KTrain.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "2d8c4e0adecca2f9bb6152916de834ccf75a0d1de20f0239611dabd3480e2716"
    },
    "kernelspec": {
      "display_name": "Python 3.9.4 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}